# Examples

Code examples for modern AI workloads and ML systems, with a focus on practical, grounded training workflows.

## Focus Areas

### Training & Fine-tuning
Primary focus on introducing training in a meaningful way:
- **TRL Examples**: RLHF and related training techniques for language models
- **Fine-tuning Workflows**: Task-specific model adaptation
- **Training Infrastructure**: Pipelines, data handling, and experiment management

### Additional Workloads
Future examples: inference optimization, data processing, model evaluation, and MLOps.

## Getting Started

Each example includes documentation, setup instructions, dependencies, and best practices.

## Included Repos (submodules)

- **Miles**: `examples/miles/miles` (`https://github.com/radixark/miles.git`)
- **Megatron-LM**: `examples/megatron-lm/megatron-lm` (`https://github.com/NVIDIA/Megatron-LM`) — NVIDIA’s GPU-optimized transformer training codebase (Megatron Core + reference training scripts).
- **AReaL**: `examples/areal/AReaL` (`https://github.com/inclusionAI/AReaL`) — lightning-fast RL for LLM reasoning/agents.
- **Awesome-ML-SYS-Tutorial**: `examples/awesome-ml-sys-tutorial/Awesome-ML-SYS-Tutorial` (`https://github.com/zhaochenyang20/Awesome-ML-SYS-Tutorial`) — ML systems / AI infra learning notes.
- **ml-systems-papers**: `examples/ml-systems-papers/ml-systems-papers` (`https://github.com/byungsoo-oh/ml-systems-papers`) — curated ML systems paper list.
- **PyTorch**: `examples/pytorch/pytorch` (`https://github.com/pytorch/pytorch`) — core PyTorch framework source.
- **FBGEMM**: `examples/fbgemm/FBGEMM` (`https://github.com/pytorch/FBGEMM`) — optimized low-precision kernels (CPU + GPU) used across DL apps.
- **torchcomms**: `examples/torchcomms/torchcomms` (`https://github.com/meta-pytorch/torchcomms`) — experimental PyTorch communications/collectives API.
- **Helion**: `examples/helion/helion` (`https://github.com/pytorch/helion`) — Python-embedded kernel DSL that compiles to Triton.
- **Awesome Production Machine Learning**: `examples/awesome-production-machine-learning/awesome-production-machine-learning` (`https://github.com/EthicalML/awesome-production-machine-learning`) — curated MLOps / production ML tools list.
- **CUDA Python**: `examples/cuda-python/cuda-python` (`https://github.com/NVIDIA/cuda-python.git`)
- **Numba-CUDA**: `examples/numba-cuda/numba-cuda` (`https://github.com/NVIDIA/numba-cuda.git`)
- **Model Optimizer (ModelOpt)**: `examples/model-optimizer/Model-Optimizer` (`https://github.com/NVIDIA/Model-Optimizer`) — NVIDIA’s open-source library for quantization/pruning/distillation/speculative decoding/sparsity workflows for inference optimization.

---

**Note**: Examples are for learning and experimentation. Adapt to your specific requirements and production constraints.
